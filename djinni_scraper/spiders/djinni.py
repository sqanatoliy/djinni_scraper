import scrapy
from scrapy_playwright.page import PageMethod
import os

LOGIN_SELECTOR = "ul > li:nth-child(1) > a.jobs-push-login-link"
EMAIL_SELECTOR = "#email"
PASSWORD_SELECTOR = "#password"
LOGIN_BUTTON_SELECTOR = 'button.btn-primary[type="submit"]'
PROFILE_SELECTOR = "div.navbar-collapse div.user-name"


class DjinniSpider(scrapy.Spider):
    name = "djinni"
    allowed_domains = ["djinni.co"]
    start_urls = ["https://djinni.co/jobs/"]
    login_url = "https://djinni.co/"
    username = "your_email@gmail.com"
    password = "your_password"

    def start_requests(self):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾, Ñ‡Ð¸ Ñ” Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ð¹ ÑÑ‚Ð°Ð½. Ð¯ÐºÑ‰Ð¾ Ñ” â€” Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾, Ñ–Ð½Ð°ÐºÑˆÐµ Ð»Ð¾Ð³Ñ–Ð½Ð¸Ð¼Ð¾ÑÑŒ."""
        if os.path.exists("state.json"):
            self.logger.info("âœ… Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ state.json! Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ñƒ ÑÐµÑÑ–ÑŽ.")
            yield scrapy.Request(
                url=self.start_urls[0],
                meta={
                    "playwright": True,
                    "playwright_context": "default",
                },
                callback=self.parse_jobs,
            )
        else:
            self.logger.info("ðŸ”„ Ð’Ð¸ÐºÐ¾Ð½ÑƒÑ”Ð¼Ð¾ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–ÑŽ...")
            yield scrapy.Request(
                url=self.login_url,
                meta={
                    "playwright": True,
                    "playwright_context": "default",
                    "playwright_include_page": True,
                },
                callback=self.login,
            )

    @staticmethod
    async def log_request(route, request):
        print(f"ðŸ“¡ Ð—Ð°Ð¿Ð¸Ñ‚: {request.url} | ÐœÐµÑ‚Ð¾Ð´: {request.method}")
        await route.continue_()

    async def login(self, response):
        """ÐŸÑ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—"""
        page = response.meta["playwright_page"]

        await page.route("**", self.log_request)
        await page.wait_for_selector(LOGIN_SELECTOR)
        await page.click(LOGIN_SELECTOR)

        await page.wait_for_timeout(3000)
        await page.fill(EMAIL_SELECTOR, self.username)
        await page.fill(PASSWORD_SELECTOR, self.password)
        storage_data = await page.evaluate("JSON.stringify(localStorage)")
        print(f"ðŸŸ¢ LocalStorage: {storage_data}")

        cookies = await page.context.cookies()
        print(f"ðŸŸ¢ Cookies: {cookies}")
        await page.click(LOGIN_BUTTON_SELECTOR)

        await page.wait_for_selector(PROFILE_SELECTOR)

        # Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ ÑÐµÑÑ–Ñ— Ð² Ñ„Ð°Ð¹Ð»
        await page.context.storage_state(path="state.json")

        await page.close()

        # Ð¢ÐµÐ¿ÐµÑ€ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ‡Ð¸ Ð»Ð¾Ð³Ñ–Ð½ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¸Ð¹
        yield scrapy.Request(
            url=self.start_urls[0],
            meta={"playwright": True, "playwright_context": "default"},
            callback=self.parse_jobs,
        )

    async def parse_jobs(self, response):
        """ÐŸÐ°Ñ€ÑÐ¸Ð¼Ð¾ Ð²Ð°ÐºÐ°Ð½ÑÑ–Ñ— Ð¿Ñ–ÑÐ»Ñ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—."""
        jobs = response.css("ul.list-jobs > li")
        for job in jobs:
            title = job.css("h2 > a::text").get(default="Not specified").strip(),
            salary = job.css("h2 > strong > span::text").get(default="Not specified").strip(),
            company = job.css("a.text-body.js-analytics-event::text").get(default="Not specified").strip(),
            views = job.css("div > div:nth-child(2) > span:nth-child(2)::text").get(default="Not specified").strip(),
            responses = job.css("div > div:nth-child(2) > span:nth-child(4)::text").get(default="Not specified").strip(),
            pub_date = job.css("div > div:nth-child(2) > span:nth-child(6)::text").get(default="Not specified").strip(),
            truncate_description = job.css("span.js-truncated-text::text").get(default="Not specified").strip(),
            tags = job.css("h2 + div::text").getall(),
            url = response.urljoin(job.css("h2 > a::attr(href)").get(default="Not specified")),
            yield {
                "title": title,
                "salary": salary,
                "company": company,
                "views": views,
                "responses": responses,
                "pub_date": pub_date,
                "truncate_description": truncate_description,
                "tags": tags,
                "url": url,
            }

        next_page = response.css("a.page-link.next::attr(href)").get()
        if next_page:
            yield response.follow(
                next_page, callback=self.parse_jobs, meta={"playwright": True, "playwright_context": "default"}
            )
